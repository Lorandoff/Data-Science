The second project is on machine learning. Here, in addition to the methods of the previous project, there are: XGBoost, CatBoost (and the selection of hyperparameters through its own system), the support vector method, the first neural networks for regression and classification, KNN, cross-validation, the selection of hyperparameters through Optuna and new metrics of model quality (new to me then).
